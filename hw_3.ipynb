{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],  # стаж\n",
    "              [500, 700, 750, 600, 1450,        # средняя стоимость занятия\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, 1, 3, 3, 1, 2]], dtype = np.float64) # квалификация репетитора\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1]) # подходит или нет репетитор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, X.shape[0]):\n",
    "    X[i] = scaler.fit_transform(X[i].reshape(-1,1)).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log (как вариант - np.clip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Logloss=-y \\ln(p) - (1-y)\\ln(1-p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = np.mean(- y * np.log(y_pred) - (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = np.mean(- y * np.log(np.clip(y_pred, 1e-5, 1)) - (1.0 - y) * \n",
    "                  np.log(np.clip((1.0 - y_pred), 1e-5, 1)))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.605170185988091"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.605170185988091"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.clip(0, 1e-2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.512925464970229"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_logloss(1, 0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Подберите аргументы функции eval_LR_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_LR_model(X, y, iterations, alpha=1e-4):\n",
    "    w_dist = np.inf\n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations + 1):\n",
    "        \n",
    "        \n",
    "        z = np.dot(w, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "    \n",
    "        w -= alpha * (1/n * np.dot((y_pred - y), X.T))        \n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, w, err)\n",
    "\n",
    "    return w, err, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = [200, 500, 1000, 2000]\n",
    "alphas = [1e-4, 1e-4, 1e-3, 1e-2, 1e-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iters': 200, 'alpha': 0.0001, 'logloss': 0.7612071473029914}\n",
      "{'iters': 200, 'alpha': 0.0001, 'logloss': 0.7612071473029914}\n",
      "{'iters': 200, 'alpha': 0.001, 'logloss': 0.7381659587792261}\n",
      "{'iters': 200, 'alpha': 0.01, 'logloss': 0.5779942810068626}\n",
      "{'iters': 200, 'alpha': 0.1, 'logloss': 0.41604957231150996}\n",
      "{'iters': 200, 'alpha': 1, 'logloss': 0.273589567007154}\n",
      "{'iters': 500, 'alpha': 0.0001, 'logloss': 0.7572558998540831}\n",
      "{'iters': 500, 'alpha': 0.0001, 'logloss': 0.7572558998540831}\n",
      "{'iters': 500, 'alpha': 0.001, 'logloss': 0.7025169340653326}\n",
      "{'iters': 500, 'alpha': 0.01, 'logloss': 0.49992247954456925}\n",
      "{'iters': 500, 'alpha': 0.1, 'logloss': 0.3516499478119723}\n",
      "{'iters': 500, 'alpha': 1, 'logloss': 0.2224106578949519}\n",
      "{'iters': 1000, 'alpha': 0.0001, 'logloss': 0.7507528681143767}\n",
      "{'iters': 1000, 'alpha': 0.0001, 'logloss': 0.7507528681143767}\n",
      "{'iters': 1000, 'alpha': 0.001, 'logloss': 0.6512037362503481}\n",
      "{'iters': 1000, 'alpha': 0.01, 'logloss': 0.46129017053513033}\n",
      "{'iters': 1000, 'alpha': 0.1, 'logloss': 0.310087838167733}\n",
      "{'iters': 1000, 'alpha': 1, 'logloss': 0.1791271033389149}\n",
      "{'iters': 2000, 'alpha': 0.0001, 'logloss': 0.7380552696739169}\n",
      "{'iters': 2000, 'alpha': 0.0001, 'logloss': 0.7380552696739169}\n",
      "{'iters': 2000, 'alpha': 0.001, 'logloss': 0.5775823746485467}\n",
      "{'iters': 2000, 'alpha': 0.01, 'logloss': 0.41579194034839995}\n",
      "{'iters': 2000, 'alpha': 0.1, 'logloss': 0.2735474180594763}\n",
      "{'iters': 2000, 'alpha': 1, 'logloss': 0.13896409150605601}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for iteration in iters:\n",
    "    for alpha in alphas:\n",
    "        w, err, i = eval_LR_model(X, y, iteration, alpha)\n",
    "        results.append({'iters': iteration, 'alpha': alpha, 'logloss': err,})\n",
    "for i in results:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод: при 2000 итерациях и $\\alpha$ = 1 _logloss_ минимальный и равен 0.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются веса, которые уже посчитаны функцией eval_LR_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.72326319, -8.10878236, -7.79840001, 18.57323654])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, err, i = eval_LR_model(X, y, 2000, 1)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(X, w):\n",
    "    return sigmoid(w.dot(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3429153 , 0.02049536, 0.99999991, 0.09461118, 0.88693524,\n",
       "       0.07049476, 1.        , 0.03636945, 0.53837445, 0.99999493])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = calc_pred_proba(X, w)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: [0 0 1 0 1 0 1 0 1 1]\n",
      "pred: [0 0 1 0 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(f'true: {y}\\npred: {np.array(list(map(round, y_pred_proba)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Если порог выбирать 0.5, то модель обучилась идеально для тестовой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются веса, которые уже посчитаны функцией eval_LR_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(X, w, target=0.5):\n",
    "    result = sigmoid(w.dot(X))\n",
    "    return np.array(list(map(lambda x: int(x>=target), result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(X, w)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Посчитайте accuracy, матрицу ошибок, precision и recall, а также F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(y, y_pred):\n",
    "    result = np.zeros((2,2))\n",
    "    to_check = list(zip(y, y_pred))\n",
    "    for i in range(len(to_check)):\n",
    "        if to_check[i][0]==0 and to_check[i][1]==0:\n",
    "            result[1][1] += 1\n",
    "        elif to_check[i][0]==1 and to_check[i][1]==1:\n",
    "            result[0][0] += 1\n",
    "        elif to_check[i][0]==1 and to_check[i][1]==0:\n",
    "            result[1][0] += 1\n",
    "        else:\n",
    "            result[0][1] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = get_confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(c_matrix):\n",
    "    precision = c_matrix[0][0] / (c_matrix[0][0] + c_matrix[0][1])\n",
    "    recall = c_matrix[0][0] / (c_matrix[0][0] + c_matrix[1][0])\n",
    "    accuracy = (c_matrix[0][0] + c_matrix[1][1]) / (c_matrix[0].sum() + c_matrix[1].sum())\n",
    "    f_1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, accuracy, f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 1.0\n",
      "recall = 0.8\n",
      "accuracy = 0.9\n",
      "f1 = 0.888888888888889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4., 0.],\n",
       "       [1., 5.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2 = calc_pred(X, w, 0.8)\n",
    "c_matrix_2 = get_confusion_matrix(y, y_pred_2)\n",
    "precision, recall, accuracy, f_1 = get_metrics(c_matrix_2)\n",
    "print(f'precision = {precision}\\nrecall = {recall}\\naccuracy = {accuracy}\\nf1 = {f_1}')\n",
    "c_matrix_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Могла, поскольку мы не ограничивали веса модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. *Создайте функции eval_LR_model_l1 и eval_LR_model_l2 с применением L1 и L2 регуляризации соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_LR_model_L2(X, y, iterations, alpha=1e-4, lambda_=1e-8):\n",
    "    w_dist = np.inf\n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations + 1):\n",
    "        \n",
    "        \n",
    "        z = np.dot(w, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "    \n",
    "        w -= alpha * ((1/n * np.dot((y_pred - y), X.T)) + 2 * lambda_ * w)\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, w, err)\n",
    "\n",
    "    return w, err, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 [ 0.73299873 -3.38317013 -1.93752529  6.18207661] 0.27358979824758417\n",
      "400 [ 1.29788374 -4.23396013 -3.05648461  8.46700999] 0.23565963170003695\n",
      "600 [ 1.75664718 -4.92776322 -3.94118191 10.30966223] 0.21122031799739122\n",
      "800 [ 2.14667862 -5.53273402 -4.69302945 11.89729018] 0.19315395824872253\n",
      "1000 [ 2.48593864 -6.07033682 -5.35074773 13.2982114 ] 0.1791283548719198\n",
      "1200 [ 2.78581465 -6.55382915 -5.9362455  14.55273736] 0.16790700138808443\n",
      "1400 [ 3.05429239 -6.99282906 -6.46428471 15.68894017] 0.1587201763817602\n",
      "1600 [ 3.29723257 -7.39467283 -6.94556604 16.72764427] 0.1510548230711767\n",
      "1800 [ 3.51905886 -7.76509291 -7.38814509 17.68479924] 0.14455496451433938\n",
      "2000 [ 3.72318232 -8.10864331 -7.79823856 18.57288303] 0.13896623448660053\n"
     ]
    }
   ],
   "source": [
    "w, _, _ = eval_LR_model_L2(X, y, 2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_LR_model_L1(X, y, iterations, alpha=1e-4, lambda_=1e-8):\n",
    "    w_dist = np.inf\n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations + 1):\n",
    "        \n",
    "        \n",
    "        z = np.dot(w, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "    \n",
    "        w -= alpha * (1/n * np.dot((y_pred - y), X.T) + lambda_ * np.sign(w))\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, w, err)\n",
    "\n",
    "    return w, err, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 [ 0.73300098 -3.38317506 -1.93752931  6.18208682] 0.2735896035014857\n",
      "400 [ 1.29789115 -4.23397293 -3.05649824  8.46704057] 0.23565919288524909\n",
      "600 [ 1.75666114 -4.92778639 -3.941208   10.30971954] 0.2112196228496254\n",
      "800 [ 2.14669998 -5.53276937 -4.69306992 11.89737864] 0.1931530215432588\n",
      "1000 [ 2.48596803 -6.07038574 -5.35080405 13.29833445] 0.17912719731175528\n",
      "1200 [ 2.78585259 -6.5538928  -5.93631896 14.55289792] 0.16790564233886898\n",
      "1400 [ 3.05433937 -6.99290846 -6.46437647 15.68914087] 0.15871863213663223\n",
      "1600 [ 3.29728901 -7.39476886 -6.94567718 16.72788751] 0.15105310686699686\n",
      "1800 [ 3.51912515 -7.76520641 -7.38827665 17.68508727] 0.1445530869943666\n",
      "2000 [ 3.72325885 -8.10877501 -7.79839156 18.57321798] 0.13896420420240133\n"
     ]
    }
   ],
   "source": [
    "w, _, _ = eval_LR_model_L1(X, y, 2000, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
